{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Detection Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow pillow numpy flask pymongo gunicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "output_dir = 'image_classification_data/fake'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "num_images = 100\n",
    "\n",
    "url = 'https://thispersondoesnotexist.com/'\n",
    "\n",
    "for i in range(num_images):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        filename = os.path.join(output_dir, f'fake_{i+1}.jpg')\n",
    "\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        print(f'Successfully downloaded {filename}')\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'Error downloading image {i+1}: {e}')\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print('Finished downloading fake images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_dir = 'image_classification_data/real'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "for i, (image, target) in enumerate(zip(lfw_people.images, lfw_people.target)):\n",
    "    filename = os.path.join(output_dir, f'real_{i}.jpg')\n",
    "    plt.imsave(filename, image, cmap='gray')\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f'Saved {i+1} images.')\n",
    "\n",
    "print(f'Finished downloading and saving {len(lfw_people.images)} real images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Deepfake Detector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 128, 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'image_classification_data',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'image_classification_data',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation')\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "EPOCHS = 15\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE)\n",
    "\n",
    "model.save('deepfake_detector_model.h5')\n",
    "\n",
    "print(\"Model training complete and saved as deepfake_detector_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the Web App (using Flask and ngrok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)  # Start ngrok when app is run\n",
    "\n",
    "MODEL_PATH = 'deepfake_detector_model.h5'\n",
    "try:\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(f\"Model '{MODEL_PATH}' loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    model = None\n",
    "\n",
    "def prepare_image(image, target_size):\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    image = image.resize(target_size)\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return '''\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Deepfake Detector</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Deepfake Detector</h1>\n",
    "        <form id=\"upload-form\" enctype=\"multipart/form-data\">\n",
    "            <input type=\"file\" name=\"file\" id=\"file-input\">\n",
    "            <button type=\"submit\">Predict</button>\n",
    "        </form>\n",
    "        <div id=\"result\"></div>\n",
    "    \n",
    "        <script>\n",
    "            document.getElementById('upload-form').addEventListener('submit', async (e) => {\n",
    "                e.preventDefault();\n",
    "                const formData = new FormData();\n",
    "                const fileInput = document.getElementById('file-input');\n",
    "                formData.append('file', fileInput.files[0]);\n",
    "    \n",
    "                const response = await fetch('/predict', {\n",
    "                    method: 'POST',\n",
    "                    body: formData\n",
    "                });\n",
    "    \n",
    "                const result = await response.json();\n",
    "    \n",
    "                const resultDiv = document.getElementById('result');\n",
    "                resultDiv.innerHTML = `<p>Prediction: ${result.prediction}</p>`;\n",
    "            });\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if model is None:\n",
    "        return jsonify({\"error\": \"Model not loaded\"}), 500\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({\"error\": \"No file part\"}), 400\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({\"error\": \"No selected file\"}), 400\n",
    "\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(file.read()))\n",
    "        prepared_image = prepare_image(image, target_size=(128, 128))\n",
    "        \n",
    "        prediction = model.predict(prepared_image)\n",
    "        prediction_label = 'Deepfake' if prediction[0][0] > 0.5 else 'Real'\n",
    "        \n",
    "        return jsonify({\"prediction\": prediction_label})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
